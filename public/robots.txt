# Robots.txt for VacyMax
# Allow all search engines to crawl the site

User-agent: *
Allow: /

# Disallow API routes and analytics
Disallow: /api/
Disallow: /_next/
Disallow: /admin/

# Point to sitemap (update domain if deploying to different environment)
Sitemap: https://vacymax.com/sitemap.xml

# Crawl-delay for aggressive bots
User-agent: Baiduspider
Crawl-delay: 5

User-agent: Yandex
Crawl-delay: 2

# Allow social media crawlers
User-agent: Twitterbot
Allow: /

User-agent: facebookexternalhit
Allow: /
